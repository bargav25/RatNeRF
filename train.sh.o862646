init meta
Loader initialized.
Number of Joints: 20
KPE: RelDist, BPE: VecNorm, VPE: VecNorm
Embedder class: <class 'core.cutoff_embedder.Embedder'>
Embedder class: <class 'core.cutoff_embedder.Embedder'>
Embedder class: <class 'core.cutoff_embedder.Embedder'>
###### 1020, 3060 and 3060 ###
RayCaster(
  (network): NeRF(
    (pts_linears): ModuleList(
      (0): Linear(in_features=4080, out_features=256, bias=True)
      (1-4): 4 x Linear(in_features=256, out_features=256, bias=True)
      (5): Linear(in_features=4336, out_features=256, bias=True)
      (6-7): 2 x Linear(in_features=256, out_features=256, bias=True)
    )
    (views_linears): ModuleList(
      (0): Linear(in_features=3316, out_features=128, bias=True)
    )
    (output_linear): Linear(in_features=256, out_features=4, bias=True)
  )
  (embed_fn): Embedder()
  (embedbones_fn): Embedder()
  (embeddirs_fn): Embedder()
)
Found ckpts []
#parameters: 2975364
done creating popt
Head direction: -y
Pose 0: Valid indices count = 40061
Invalid bounding box for pose 1. Falling back to full image.
Pose 1: Valid indices count = 1391744
Pose 2: Valid indices count = 61791
Pose 3: Valid indices count = 1380
Invalid bounding box for pose 4. Falling back to full image.
Pose 4: Valid indices count = 1391744
Pose 5: Valid indices count = 179907
Pose 6: Valid indices count = 276148
Pose 7: Valid indices count = 200184
Pose 8: Valid indices count = 308052
Pose 9: Valid indices count = 167160
Pose 10: Valid indices count = 178724
Pose 11: Valid indices count = 179216
Pose 12: Valid indices count = 179463
Pose 13: Valid indices count = 177996
Pose 14: Valid indices count = 179340
Valid indices across all poses: [tensor([ 175236,  175237,  175238,  ..., 1075676, 1075677, 1075678]), tensor([      0,       1,       2,  ..., 1391741, 1391742, 1391743]), tensor([  1198,   1199,   1200,  ..., 636108, 636109, 636110]), tensor([ 63740,  63741,  63742,  ..., 673292, 673293, 673294]), tensor([      0,       1,       2,  ..., 1391741, 1391742, 1391743]), tensor([ 274622,  274623,  274624,  ..., 1148716, 1148717, 1148718]), tensor([264970, 264971, 264972,  ..., 960038, 960039, 960040]), tensor([173409, 173410, 173411,  ..., 778085, 778086, 778087]), tensor([   715,    716,    717,  ..., 685229, 685230, 685231]), tensor([153600, 153601, 153602,  ..., 710427, 710428, 710429]), tensor([315699, 315700, 315701,  ..., 966780, 966781, 966782]), tensor([315695, 315696, 315697,  ..., 961468, 961469, 961470]), tensor([314368, 314369, 314370,  ..., 962796, 962797, 962798]), tensor([319683, 319684, 319685,  ..., 968108, 968109, 968110]), tensor([315697, 315698, 315699,  ..., 965452, 965453, 965454])]
0 0.000408172607421875
1 1.7776973247528076
2 61.73465585708618
3 2.7504653930664062
4 0.05995011329650879
5 61.925679206848145
6 8.007227897644043
7 12.296096801757812
8 8.899438619613647
9 13.701857805252075
10 7.435423374176025
11 7.947839260101318
12 7.974544525146484
13 7.99536919593811
14 7.92065167427063
Predicted image shape (th_rgbs): torch.Size([15, 3, 1048, 1328])
Ground truth image shape (th_gt): torch.Size([15, 3, 1048, 1328])
Any NaNs in th_rgbs: tensor(False, device='cpu')
Any NaNs in th_gt: tensor(False, device='cpu')
Any Infs in th_rgbs: tensor(False, device='cpu')
Any Infs in th_gt: tensor(False, device='cpu')
Evaluate PSNR: 6.26692287573839 (7.141327449388544), SSIM: 0.744624674320221 (0.6432351270794422)
[TRAIN] Iter: 100 Loss: 0.12883839011192322  PSNR: 8.89954662322998, Alpha: 1.0, GradNorm 0.06150618892167837, Mem: 16231.01611328125
[TRAIN] Iter: 200 Loss: 0.1391366869211197  PSNR: 8.565583229064941, Alpha: 1.0, GradNorm 0.08113417619690917, Mem: 16231.01611328125
[TRAIN] Iter: 300 Loss: 0.11943668872117996  PSNR: 9.228621482849121, Alpha: 1.0, GradNorm 0.03781287603560355, Mem: 16231.01611328125
[TRAIN] Iter: 400 Loss: 0.12717945873737335  PSNR: 8.955830574035645, Alpha: 1.0, GradNorm 0.0790918572558999, Mem: 16231.01611328125
[TRAIN] Iter: 500 Loss: 0.12479027360677719  PSNR: 9.038191795349121, Alpha: 1.0, GradNorm 0.0487596113270835, Mem: 16231.01611328125
[TRAIN] Iter: 600 Loss: 0.11961057782173157  PSNR: 9.222304344177246, Alpha: 1.0, GradNorm 0.0671164102351883, Mem: 16231.01611328125
[TRAIN] Iter: 700 Loss: 0.12825168669223785  PSNR: 8.9193696975708, Alpha: 1.0, GradNorm 0.023866341001727756, Mem: 16231.01611328125
[TRAIN] Iter: 800 Loss: 0.12041298300027847  PSNR: 9.193266868591309, Alpha: 1.0, GradNorm 0.044367890377595996, Mem: 16231.01611328125
[TRAIN] Iter: 900 Loss: 0.1266787052154541  PSNR: 8.972963333129883, Alpha: 1.0, GradNorm 0.03215729286821002, Mem: 16231.01611328125
[TRAIN] Iter: 1000 Loss: 0.13276375830173492  PSNR: 8.769204139709473, Alpha: 1.0, GradNorm 0.02713798179529997, Mem: 16231.01611328125
[TRAIN] Iter: 1100 Loss: 0.12562823295593262  PSNR: 9.009127616882324, Alpha: 1.0, GradNorm 0.07183480968672748, Mem: 16231.01611328125
[TRAIN] Iter: 1200 Loss: 0.11964157223701477  PSNR: 9.221179008483887, Alpha: 1.0, GradNorm 0.0999890407417317, Mem: 16231.01611328125
[TRAIN] Iter: 1300 Loss: 0.11292651295661926  PSNR: 9.472041130065918, Alpha: 1.0, GradNorm 0.04632571294013294, Mem: 16231.01611328125
[TRAIN] Iter: 1400 Loss: 0.12503546476364136  PSNR: 9.029667854309082, Alpha: 1.0, GradNorm 0.0723839457829179, Mem: 16231.01611328125
[TRAIN] Iter: 1500 Loss: 0.13330049812793732  PSNR: 8.75168228149414, Alpha: 1.0, GradNorm 0.09356217462473958, Mem: 16231.01611328125
[TRAIN] Iter: 1600 Loss: 0.13719409704208374  PSNR: 8.626646041870117, Alpha: 1.0, GradNorm 0.06568974511624032, Mem: 16231.01611328125
[TRAIN] Iter: 1700 Loss: 0.1278633028268814  PSNR: 8.932539939880371, Alpha: 1.0, GradNorm 0.02829833594357681, Mem: 16231.01611328125
[TRAIN] Iter: 1800 Loss: 0.11982230097055435  PSNR: 9.214622497558594, Alpha: 1.0, GradNorm 0.03718179383902157, Mem: 16231.01611328125
[TRAIN] Iter: 1900 Loss: 0.1217947006225586  PSNR: 9.143715858459473, Alpha: 1.0, GradNorm 0.0628862644156197, Mem: 16231.01611328125
[TRAIN] Iter: 2000 Loss: 0.13181419670581818  PSNR: 8.80037784576416, Alpha: 1.0, GradNorm 0.04623518481761403, Mem: 16231.01611328125
[TRAIN] Iter: 2100 Loss: 0.12414661794900894  PSNR: 9.060650825500488, Alpha: 1.0, GradNorm 0.049514044516769516, Mem: 16231.01611328125
[TRAIN] Iter: 2200 Loss: 0.12190893292427063  PSNR: 9.139644622802734, Alpha: 1.0, GradNorm 0.036608254083921495, Mem: 16231.01611328125
[TRAIN] Iter: 2300 Loss: 0.119696244597435  PSNR: 9.219194412231445, Alpha: 1.0, GradNorm 0.033223590319063655, Mem: 16231.01611328125
[TRAIN] Iter: 2400 Loss: 0.13099461793899536  PSNR: 8.827465057373047, Alpha: 1.0, GradNorm 0.03560707001245961, Mem: 16231.01611328125
[TRAIN] Iter: 2500 Loss: 0.11907870322465897  PSNR: 9.241659164428711, Alpha: 1.0, GradNorm 0.044111579075928685, Mem: 16231.01611328125
[TRAIN] Iter: 2600 Loss: 0.12245319038629532  PSNR: 9.120298385620117, Alpha: 1.0, GradNorm 0.057709779719158645, Mem: 16231.01611328125
[TRAIN] Iter: 2700 Loss: 0.14373762905597687  PSNR: 8.424295425415039, Alpha: 1.0, GradNorm 0.05413477155832922, Mem: 16231.01611328125
[TRAIN] Iter: 2800 Loss: 0.12710711359977722  PSNR: 8.958300590515137, Alpha: 1.0, GradNorm 0.0549777663325146, Mem: 16231.01611328125
[TRAIN] Iter: 2900 Loss: 0.1408623456954956  PSNR: 8.51205062866211, Alpha: 1.0, GradNorm 0.058414223754875885, Mem: 16231.01611328125
[TRAIN] Iter: 3000 Loss: 0.13206298649311066  PSNR: 8.79218864440918, Alpha: 1.0, GradNorm 0.04975657464457353, Mem: 16231.01611328125
[TRAIN] Iter: 3100 Loss: 0.10896684229373932  PSNR: 9.627055168151855, Alpha: 1.0, GradNorm 0.047328831467492796, Mem: 16231.01611328125
[TRAIN] Iter: 3200 Loss: 0.13561275601387024  PSNR: 8.676994323730469, Alpha: 1.0, GradNorm 0.0428173285170441, Mem: 16231.01611328125
[TRAIN] Iter: 3300 Loss: 0.1317320168018341  PSNR: 8.803086280822754, Alpha: 1.0, GradNorm 0.043440901821626875, Mem: 16231.01611328125
[TRAIN] Iter: 3400 Loss: 0.1272730529308319  PSNR: 8.952634811401367, Alpha: 1.0, GradNorm 0.03476178739726421, Mem: 16231.01611328125
[TRAIN] Iter: 3500 Loss: 0.13097059726715088  PSNR: 8.828262329101562, Alpha: 1.0, GradNorm 0.047292815669819216, Mem: 16231.01611328125
[TRAIN] Iter: 3600 Loss: 0.1292976289987564  PSNR: 8.88409423828125, Alpha: 1.0, GradNorm 0.07478137019963241, Mem: 16231.01611328125
[TRAIN] Iter: 3700 Loss: 0.11226781457662582  PSNR: 9.497446060180664, Alpha: 1.0, GradNorm 0.038921474323750746, Mem: 16231.01611328125
[TRAIN] Iter: 3800 Loss: 0.13006363809108734  PSNR: 8.858441352844238, Alpha: 1.0, GradNorm 0.05470356234411794, Mem: 16231.01611328125
[TRAIN] Iter: 3900 Loss: 0.13680022954940796  PSNR: 8.639131546020508, Alpha: 1.0, GradNorm 0.03456569406555471, Mem: 16231.01611328125
[TRAIN] Iter: 4000 Loss: 0.121470145881176  PSNR: 9.155303955078125, Alpha: 1.0, GradNorm 0.0557407647077668, Mem: 16231.01611328125
[TRAIN] Iter: 4100 Loss: 0.11974520236253738  PSNR: 9.217418670654297, Alpha: 1.0, GradNorm 0.0514587068395683, Mem: 16231.01611328125
[TRAIN] Iter: 4200 Loss: 0.13664668798446655  PSNR: 8.64400863647461, Alpha: 1.0, GradNorm 0.0481598092102142, Mem: 16231.01611328125
[TRAIN] Iter: 4300 Loss: 0.13211530447006226  PSNR: 8.7904691696167, Alpha: 1.0, GradNorm 0.06139103501646763, Mem: 16231.01611328125
[TRAIN] Iter: 4400 Loss: 0.13013482093811035  PSNR: 8.856064796447754, Alpha: 1.0, GradNorm 0.044061644092906686, Mem: 16231.01611328125
[TRAIN] Iter: 4500 Loss: 0.12040641903877258  PSNR: 9.193503379821777, Alpha: 1.0, GradNorm 0.07203209039199528, Mem: 16231.01611328125
[TRAIN] Iter: 4600 Loss: 0.1282438188791275  PSNR: 8.919634819030762, Alpha: 1.0, GradNorm 0.09795439193420108, Mem: 16231.01611328125
[TRAIN] Iter: 4700 Loss: 0.12911275029182434  PSNR: 8.89030933380127, Alpha: 1.0, GradNorm 0.04220203581551852, Mem: 16231.01611328125
[TRAIN] Iter: 4800 Loss: 0.13084374368190765  PSNR: 8.832469940185547, Alpha: 1.0, GradNorm 0.08758039661434884, Mem: 16231.01611328125
[TRAIN] Iter: 4900 Loss: 0.12835069000720978  PSNR: 8.916017532348633, Alpha: 1.0, GradNorm 0.04750592704595794, Mem: 16231.01611328125
[TRAIN] Iter: 5000 Loss: 0.12836475670337677  PSNR: 8.915541648864746, Alpha: 1.0, GradNorm 0.051886996354611796, Mem: 16231.01611328125
[TRAIN] Iter: 5100 Loss: 0.1255800426006317  PSNR: 9.010793685913086, Alpha: 1.0, GradNorm 0.07168443535628015, Mem: 16231.01611328125
[TRAIN] Iter: 5200 Loss: 0.1177758127450943  PSNR: 9.289438247680664, Alpha: 1.0, GradNorm 0.0679196560941699, Mem: 16231.01611328125
[TRAIN] Iter: 5300 Loss: 0.13287203013896942  PSNR: 8.765664100646973, Alpha: 1.0, GradNorm 0.047999625421278655, Mem: 16231.01611328125
[TRAIN] Iter: 5400 Loss: 0.1256643831729889  PSNR: 9.007877349853516, Alpha: 1.0, GradNorm 0.06910560329151767, Mem: 16231.01611328125
[TRAIN] Iter: 5500 Loss: 0.10967394709587097  PSNR: 9.59896469116211, Alpha: 1.0, GradNorm 0.023721470640948396, Mem: 16231.01611328125
[TRAIN] Iter: 5600 Loss: 0.12174715101718903  PSNR: 9.14541244506836, Alpha: 1.0, GradNorm 0.0443520042947818, Mem: 16231.01611328125
[TRAIN] Iter: 5700 Loss: 0.138663649559021  PSNR: 8.580373764038086, Alpha: 1.0, GradNorm 0.0668265680436643, Mem: 16231.01611328125
[TRAIN] Iter: 5800 Loss: 0.13711895048618317  PSNR: 8.629024505615234, Alpha: 1.0, GradNorm 0.114063025946452, Mem: 16231.01611328125
[TRAIN] Iter: 5900 Loss: 0.12347868084907532  PSNR: 9.08407974243164, Alpha: 1.0, GradNorm 0.08486443881458106, Mem: 16231.01611328125
[TRAIN] Iter: 6000 Loss: 0.126256063580513  PSNR: 8.98747730255127, Alpha: 1.0, GradNorm 0.03543348771068928, Mem: 16231.01611328125
[TRAIN] Iter: 6100 Loss: 0.13867729902267456  PSNR: 8.57994556427002, Alpha: 1.0, GradNorm 0.07235100698357978, Mem: 16231.01611328125
[TRAIN] Iter: 6200 Loss: 0.13134045898914337  PSNR: 8.816014289855957, Alpha: 1.0, GradNorm 0.05455172390243475, Mem: 16231.01611328125
[TRAIN] Iter: 6300 Loss: 0.12489216774702072  PSNR: 9.034648895263672, Alpha: 1.0, GradNorm 0.04267011963217267, Mem: 16231.01611328125
[TRAIN] Iter: 6400 Loss: 0.1227187067270279  PSNR: 9.110892295837402, Alpha: 1.0, GradNorm 0.033996520522208674, Mem: 16231.01611328125
[TRAIN] Iter: 6500 Loss: 0.12746989727020264  PSNR: 8.945923805236816, Alpha: 1.0, GradNorm 0.0559442776980626, Mem: 16231.01611328125
[TRAIN] Iter: 6600 Loss: 0.1307719349861145  PSNR: 8.834853172302246, Alpha: 1.0, GradNorm 0.06687507396979689, Mem: 16231.01611328125
[TRAIN] Iter: 6700 Loss: 0.12302372604608536  PSNR: 9.10011100769043, Alpha: 1.0, GradNorm 0.055170517132415754, Mem: 16231.01611328125
[TRAIN] Iter: 6800 Loss: 0.12512768805027008  PSNR: 9.026466369628906, Alpha: 0.9998927116394043, GradNorm 0.061910913102384335, Mem: 16231.01611328125
[TRAIN] Iter: 6900 Loss: 0.13370127975940704  PSNR: 8.738643646240234, Alpha: 1.0, GradNorm 0.09040900174547538, Mem: 16231.01611328125
[TRAIN] Iter: 7000 Loss: 0.11876408010721207  PSNR: 9.253148078918457, Alpha: 1.0, GradNorm 0.08200211235834848, Mem: 16231.01611328125
[TRAIN] Iter: 7100 Loss: 0.12483683973550797  PSNR: 9.036571502685547, Alpha: 1.0, GradNorm 0.06941759272915952, Mem: 16231.01611328125
[TRAIN] Iter: 7200 Loss: 0.12379826605319977  PSNR: 9.072854042053223, Alpha: 1.0, GradNorm 0.05510682458724833, Mem: 16231.01611328125
[TRAIN] Iter: 7300 Loss: 0.11245415359735489  PSNR: 9.49024486541748, Alpha: 1.0, GradNorm 0.0698329364799906, Mem: 16231.01611328125
[TRAIN] Iter: 7400 Loss: 0.1328994780778885  PSNR: 8.764766693115234, Alpha: 1.0, GradNorm 0.0485162362651579, Mem: 16231.01611328125
[TRAIN] Iter: 7500 Loss: 0.12371288239955902  PSNR: 9.075850486755371, Alpha: 0.9999992251396179, GradNorm 0.09688605712892143, Mem: 16231.01611328125
[TRAIN] Iter: 7600 Loss: 0.11673186719417572  PSNR: 9.328105926513672, Alpha: 0.9999626874923706, GradNorm 0.08419545426468758, Mem: 16231.01611328125
[TRAIN] Iter: 7700 Loss: 0.11955560743808746  PSNR: 9.224300384521484, Alpha: 1.0, GradNorm 0.03985118588315591, Mem: 16231.01611328125
[TRAIN] Iter: 7800 Loss: 0.11015664041042328  PSNR: 9.579894065856934, Alpha: 1.0, GradNorm 0.06937542690499778, Mem: 16231.01611328125
[TRAIN] Iter: 7900 Loss: 0.126514732837677  PSNR: 8.978588104248047, Alpha: 0.9999997019767761, GradNorm 0.0634056166822576, Mem: 16231.01611328125
[TRAIN] Iter: 8000 Loss: 0.13142819702625275  PSNR: 8.813115119934082, Alpha: 1.0, GradNorm 0.06389051985885315, Mem: 16231.01611328125
[TRAIN] Iter: 8100 Loss: 0.1326555609703064  PSNR: 8.772745132446289, Alpha: 1.0, GradNorm 0.08102274307840387, Mem: 16231.01611328125
[TRAIN] Iter: 8200 Loss: 0.12388668954372406  PSNR: 9.069753646850586, Alpha: 1.0, GradNorm 0.1027911379254391, Mem: 16231.01611328125
[TRAIN] Iter: 8300 Loss: 0.10778623819351196  PSNR: 9.67436695098877, Alpha: 1.0, GradNorm 0.10345656244969464, Mem: 16231.01611328125
[TRAIN] Iter: 8400 Loss: 0.12242565304040909  PSNR: 9.121275901794434, Alpha: 1.0, GradNorm 0.07364175092452774, Mem: 16231.01611328125
[TRAIN] Iter: 8500 Loss: 0.10879907757043839  PSNR: 9.633747100830078, Alpha: 0.9997817873954773, GradNorm 0.14505073905585303, Mem: 16231.01611328125
[TRAIN] Iter: 8600 Loss: 0.11584070324897766  PSNR: 9.361388206481934, Alpha: 0.9999996423721313, GradNorm 0.13562063359874946, Mem: 16231.01611328125
[TRAIN] Iter: 8700 Loss: 0.12201918661594391  PSNR: 9.13571834564209, Alpha: 1.0, GradNorm 0.09200727605173842, Mem: 16231.01611328125
[TRAIN] Iter: 8800 Loss: 0.12285659462213516  PSNR: 9.106016159057617, Alpha: 1.0, GradNorm 0.1032281636562786, Mem: 16231.01611328125
[TRAIN] Iter: 8900 Loss: 0.11701815575361252  PSNR: 9.31746768951416, Alpha: 1.0, GradNorm 0.05975405645926244, Mem: 16231.01611328125
[TRAIN] Iter: 9000 Loss: 0.1271858960390091  PSNR: 8.955609321594238, Alpha: 0.9999997615814209, GradNorm 0.15926986194549864, Mem: 16231.01611328125
[TRAIN] Iter: 9100 Loss: 0.11752629280090332  PSNR: 9.298649787902832, Alpha: 1.0, GradNorm 0.12401353809365405, Mem: 16231.01611328125
[TRAIN] Iter: 9200 Loss: 0.11674796044826508  PSNR: 9.327507019042969, Alpha: 1.0, GradNorm 0.17657774131270837, Mem: 16231.01611328125
[TRAIN] Iter: 9300 Loss: 0.129257470369339  PSNR: 8.885443687438965, Alpha: 1.0, GradNorm 0.10758883343291925, Mem: 16231.01611328125
[TRAIN] Iter: 9400 Loss: 0.11880169063806534  PSNR: 9.2517728805542, Alpha: 1.0, GradNorm 0.11198405519428418, Mem: 16231.01611328125
[TRAIN] Iter: 9500 Loss: 0.11855322867631912  PSNR: 9.260865211486816, Alpha: 1.0, GradNorm 0.11462379540071982, Mem: 16231.01611328125
[TRAIN] Iter: 9600 Loss: 0.10463171452283859  PSNR: 9.803366661071777, Alpha: 1.0, GradNorm 0.10246697786593773, Mem: 16231.01611328125
[TRAIN] Iter: 9700 Loss: 0.11084988713264465  PSNR: 9.55264663696289, Alpha: 0.999980092048645, GradNorm 0.0955429647046617, Mem: 16231.01611328125
[TRAIN] Iter: 9800 Loss: 0.11357264965772629  PSNR: 9.447261810302734, Alpha: 1.0, GradNorm 0.13439982636210537, Mem: 16231.01611328125
[TRAIN] Iter: 9900 Loss: 0.11783365160226822  PSNR: 9.28730583190918, Alpha: 0.999997615814209, GradNorm 0.09619851134874223, Mem: 16231.01611328125
Saved checkpoints at logs/rats_model/010000.tar
Head direction: -y
Pose 0: Valid indices count = 40061
Invalid bounding box for pose 1. Falling back to full image.
Pose 1: Valid indices count = 1391744
Pose 2: Valid indices count = 61791
Pose 3: Valid indices count = 1380
Invalid bounding box for pose 4. Falling back to full image.
Pose 4: Valid indices count = 1391744
Pose 5: Valid indices count = 179907
Pose 6: Valid indices count = 276148
Pose 7: Valid indices count = 200184
Pose 8: Valid indices count = 308052
Pose 9: Valid indices count = 167160
Pose 10: Valid indices count = 178724
Pose 11: Valid indices count = 179216
Pose 12: Valid indices count = 179463
Pose 13: Valid indices count = 177996
Pose 14: Valid indices count = 179340
Valid indices across all poses: [tensor([ 175236,  175237,  175238,  ..., 1075676, 1075677, 1075678]), tensor([      0,       1,       2,  ..., 1391741, 1391742, 1391743]), tensor([  1198,   1199,   1200,  ..., 636108, 636109, 636110]), tensor([ 63740,  63741,  63742,  ..., 673292, 673293, 673294]), tensor([      0,       1,       2,  ..., 1391741, 1391742, 1391743]), tensor([ 274622,  274623,  274624,  ..., 1148716, 1148717, 1148718]), tensor([264970, 264971, 264972,  ..., 960038, 960039, 960040]), tensor([173409, 173410, 173411,  ..., 778085, 778086, 778087]), tensor([   715,    716,    717,  ..., 685229, 685230, 685231]), tensor([153600, 153601, 153602,  ..., 710427, 710428, 710429]), tensor([315699, 315700, 315701,  ..., 966780, 966781, 966782]), tensor([315695, 315696, 315697,  ..., 961468, 961469, 961470]), tensor([314368, 314369, 314370,  ..., 962796, 962797, 962798]), tensor([319683, 319684, 319685,  ..., 968108, 968109, 968110]), tensor([315697, 315698, 315699,  ..., 965452, 965453, 965454])]
0 0.0012257099151611328
1 1.775270938873291
2 61.85907983779907
3 2.7518417835235596
4 0.05582618713378906
5 62.04485750198364
6 8.020009517669678
7 12.29832935333252
8 8.907371997833252
9 13.725720167160034
10 7.445003032684326
11 7.959298372268677
12 7.982276678085327
13 7.998885631561279
14 7.929867744445801
Predicted image shape (th_rgbs): torch.Size([15, 3, 1048, 1328])
Ground truth image shape (th_gt): torch.Size([15, 3, 1048, 1328])
Any NaNs in th_rgbs: tensor(False, device='cpu')
Any NaNs in th_gt: tensor(False, device='cpu')
Any Infs in th_rgbs: tensor(False, device='cpu')
Any Infs in th_gt: tensor(False, device='cpu')
Evaluate PSNR: 11.723901601360959 (7.70161953332212), SSIM: 0.8640149235725403 (0.6615251010907165)
[TRAIN] Iter: 10000 Loss: 0.13007766008377075  PSNR: 8.857973098754883, Alpha: 1.0, GradNorm 0.15900495093290867, Mem: 16231.0166015625
[TRAIN] Iter: 10100 Loss: 0.12974630296230316  PSNR: 8.869050025939941, Alpha: 0.9999995231628418, GradNorm 0.12537727853362662, Mem: 16231.0166015625
[TRAIN] Iter: 10200 Loss: 0.12748415768146515  PSNR: 8.94543743133545, Alpha: 1.0, GradNorm 0.14443935870309027, Mem: 16231.0166015625
[TRAIN] Iter: 10300 Loss: 0.11419656872749329  PSNR: 9.423469543457031, Alpha: 1.0, GradNorm 0.14468942060129886, Mem: 16231.0166015625
[TRAIN] Iter: 10400 Loss: 0.12513764202594757  PSNR: 9.02612018585205, Alpha: 0.9999982714653015, GradNorm 0.1910789468859877, Mem: 16231.0166015625
[TRAIN] Iter: 10500 Loss: 0.11671328544616699  PSNR: 9.32879638671875, Alpha: 1.0, GradNorm 0.19237126965757825, Mem: 16231.0166015625
[TRAIN] Iter: 10600 Loss: 0.11874371021986008  PSNR: 9.253893852233887, Alpha: 1.0, GradNorm 0.2646849369379284, Mem: 16231.0166015625
[TRAIN] Iter: 10700 Loss: 0.11881981790065765  PSNR: 9.251111030578613, Alpha: 1.0, GradNorm 0.07577635738485466, Mem: 16231.0166015625
[TRAIN] Iter: 10800 Loss: 0.11279845237731934  PSNR: 9.476968765258789, Alpha: 0.9999603033065796, GradNorm 0.170579527466138, Mem: 16231.0166015625
[TRAIN] Iter: 10900 Loss: 0.13106851279735565  PSNR: 8.825016021728516, Alpha: 0.9999999403953552, GradNorm 0.25596821909888495, Mem: 16231.0166015625
[TRAIN] Iter: 11000 Loss: 0.1043773889541626  PSNR: 9.813936233520508, Alpha: 0.9999982714653015, GradNorm 0.19042490934324022, Mem: 16231.0166015625
[TRAIN] Iter: 11100 Loss: 0.11801310628652573  PSNR: 9.280696868896484, Alpha: 0.9999805688858032, GradNorm 0.20363561660362955, Mem: 16231.0166015625
[TRAIN] Iter: 11200 Loss: 0.11183847486972809  PSNR: 9.514087677001953, Alpha: 0.9999954700469971, GradNorm 0.12569507787182438, Mem: 16231.0166015625
[TRAIN] Iter: 11300 Loss: 0.12638984620571136  PSNR: 8.982877731323242, Alpha: 1.0, GradNorm 0.14577240035767688, Mem: 16231.0166015625
[TRAIN] Iter: 11400 Loss: 0.1322334259748459  PSNR: 8.78658676147461, Alpha: 0.9998400211334229, GradNorm 0.19910856936960744, Mem: 16231.0166015625
[TRAIN] Iter: 11500 Loss: 0.12524113059043884  PSNR: 9.022530555725098, Alpha: 0.999985933303833, GradNorm 0.08295628389151981, Mem: 16231.0166015625
[TRAIN] Iter: 11600 Loss: 0.11941581219434738  PSNR: 9.229382514953613, Alpha: 0.9999998807907104, GradNorm 0.22684404897494795, Mem: 16231.0166015625
[TRAIN] Iter: 11700 Loss: 0.13548167049884796  PSNR: 8.681194305419922, Alpha: 1.0, GradNorm 0.23687202409099142, Mem: 16231.0166015625
[TRAIN] Iter: 11800 Loss: 0.0995347648859024  PSNR: 10.020252227783203, Alpha: 1.0, GradNorm 0.08323832318221015, Mem: 16231.0166015625
[TRAIN] Iter: 11900 Loss: 0.12147542089223862  PSNR: 9.155116081237793, Alpha: 0.9999984502792358, GradNorm 0.18941472808564697, Mem: 16231.0166015625
[TRAIN] Iter: 12000 Loss: 0.1288088709115982  PSNR: 8.900541305541992, Alpha: 0.9999977946281433, GradNorm 0.22872910091093523, Mem: 16231.0166015625
[TRAIN] Iter: 12100 Loss: 0.10526972264051437  PSNR: 9.776965141296387, Alpha: 1.0, GradNorm 0.18989665277981094, Mem: 16231.0166015625
[TRAIN] Iter: 12200 Loss: 0.11160358041524887  PSNR: 9.523219108581543, Alpha: 1.0, GradNorm 0.15913617418568415, Mem: 16231.0166015625
[TRAIN] Iter: 12300 Loss: 0.11239027976989746  PSNR: 9.492712020874023, Alpha: 1.0, GradNorm 0.20209173138335276, Mem: 16231.0166015625
[TRAIN] Iter: 12400 Loss: 0.11360287666320801  PSNR: 9.446106910705566, Alpha: 0.9999954700469971, GradNorm 0.16829879099057393, Mem: 16231.0166015625
[TRAIN] Iter: 12500 Loss: 0.1311981976032257  PSNR: 8.820720672607422, Alpha: 0.9999998807907104, GradNorm 0.2701298033721153, Mem: 16231.0166015625
[TRAIN] Iter: 12600 Loss: 0.10779117047786713  PSNR: 9.674168586730957, Alpha: 0.9999997019767761, GradNorm 0.24254139378540812, Mem: 16231.0166015625
[TRAIN] Iter: 12700 Loss: 0.12560367584228516  PSNR: 9.009977340698242, Alpha: 0.9999994039535522, GradNorm 0.1462895033635113, Mem: 16231.0166015625
[TRAIN] Iter: 12800 Loss: 0.11853693425655365  PSNR: 9.261462211608887, Alpha: 0.9999935030937195, GradNorm 0.1062266384982622, Mem: 16231.0166015625
[TRAIN] Iter: 12900 Loss: 0.13347171247005463  PSNR: 8.74610710144043, Alpha: 0.9999715685844421, GradNorm 0.35006971049651914, Mem: 16231.0166015625
[TRAIN] Iter: 13000 Loss: 0.13131268322467804  PSNR: 8.816933631896973, Alpha: 1.0, GradNorm 0.26707446094426696, Mem: 16231.0166015625
[TRAIN] Iter: 13100 Loss: 0.1189844086766243  PSNR: 9.245099067687988, Alpha: 1.0, GradNorm 0.22325239897382876, Mem: 16231.0166015625
[TRAIN] Iter: 13200 Loss: 0.1028372198343277  PSNR: 9.878496170043945, Alpha: 0.9999946355819702, GradNorm 0.22959279704492647, Mem: 16231.0166015625
[TRAIN] Iter: 13300 Loss: 0.11862977594137192  PSNR: 9.258063316345215, Alpha: 1.0, GradNorm 0.305548715413768, Mem: 16231.0166015625
[TRAIN] Iter: 13400 Loss: 0.11630436033010483  PSNR: 9.344039916992188, Alpha: 1.0, GradNorm 0.2310597560245116, Mem: 16231.0166015625
[TRAIN] Iter: 13500 Loss: 0.11400636285543442  PSNR: 9.430708885192871, Alpha: 0.9997772574424744, GradNorm 0.16468910310891058, Mem: 16231.0166015625
[TRAIN] Iter: 13600 Loss: 0.10894100368022919  PSNR: 9.62808609008789, Alpha: 0.9999715685844421, GradNorm 0.17568727650829213, Mem: 16231.0166015625
[TRAIN] Iter: 13700 Loss: 0.1106516420841217  PSNR: 9.560420989990234, Alpha: 0.9997613430023193, GradNorm 0.09643216710649524, Mem: 16231.0166015625
[TRAIN] Iter: 13800 Loss: 0.11118096858263016  PSNR: 9.539695739746094, Alpha: 1.0, GradNorm 0.18069891010320313, Mem: 16231.0166015625
[TRAIN] Iter: 13900 Loss: 0.11450640112161636  PSNR: 9.411702156066895, Alpha: 1.0, GradNorm 0.219121532080249, Mem: 16231.0166015625
[TRAIN] Iter: 14000 Loss: 0.11589241027832031  PSNR: 9.35944938659668, Alpha: 1.0, GradNorm 0.30865490638888476, Mem: 16231.0166015625
[TRAIN] Iter: 14100 Loss: 0.11009082943201065  PSNR: 9.582488059997559, Alpha: 0.9999641180038452, GradNorm 0.31339648406273946, Mem: 16231.0166015625
[TRAIN] Iter: 14200 Loss: 0.0999666079878807  PSNR: 10.001450538635254, Alpha: 0.9999999403953552, GradNorm 0.28001005621179675, Mem: 16231.0166015625
[TRAIN] Iter: 14300 Loss: 0.11094208806753159  PSNR: 9.549036026000977, Alpha: 0.9999997615814209, GradNorm 0.17762490825350288, Mem: 16231.0166015625
[TRAIN] Iter: 14400 Loss: 0.10511046648025513  PSNR: 9.783540725708008, Alpha: 0.9999938011169434, GradNorm 0.22223937311649125, Mem: 16231.0166015625
[TRAIN] Iter: 14500 Loss: 0.1128602996468544  PSNR: 9.474588394165039, Alpha: 0.9999570846557617, GradNorm 0.2025882381447759, Mem: 16231.0166015625
[TRAIN] Iter: 14600 Loss: 0.12641921639442444  PSNR: 8.981868743896484, Alpha: 0.9999999403953552, GradNorm 0.2710346651070052, Mem: 16231.0166015625
[TRAIN] Iter: 14700 Loss: 0.1237802803516388  PSNR: 9.073484420776367, Alpha: 1.0, GradNorm 0.4999936971905673, Mem: 16231.0166015625
[TRAIN] Iter: 14800 Loss: 0.09245544672012329  PSNR: 10.34067440032959, Alpha: 0.9999997615814209, GradNorm 0.13518763213254864, Mem: 16231.0166015625
[TRAIN] Iter: 14900 Loss: 0.12231116741895676  PSNR: 9.125338554382324, Alpha: 0.9999756813049316, GradNorm 0.24259872736592566, Mem: 16231.0166015625
[TRAIN] Iter: 15000 Loss: 0.11925768852233887  PSNR: 9.235136032104492, Alpha: 1.0, GradNorm 0.21353230955805175, Mem: 16231.0166015625
[TRAIN] Iter: 15100 Loss: 0.10243277996778488  PSNR: 9.895609855651855, Alpha: 1.0, GradNorm 0.12778636931758328, Mem: 16231.0166015625
[TRAIN] Iter: 15200 Loss: 0.1216832771897316  PSNR: 9.147690773010254, Alpha: 0.9734034538269043, GradNorm 0.7407308622428808, Mem: 16231.0166015625
[TRAIN] Iter: 15300 Loss: 0.1119915246963501  PSNR: 9.508148193359375, Alpha: 1.0, GradNorm 0.15640479663560017, Mem: 16231.0166015625
[TRAIN] Iter: 15400 Loss: 0.0989406630396843  PSNR: 10.046252250671387, Alpha: 1.0, GradNorm 0.23700469721407977, Mem: 16231.0166015625
[TRAIN] Iter: 15500 Loss: 0.0945514366030693  PSNR: 10.243318557739258, Alpha: 1.0, GradNorm 0.16196755111534347, Mem: 16231.0166015625
[TRAIN] Iter: 15600 Loss: 0.09703413397073746  PSNR: 10.130753517150879, Alpha: 0.9999903440475464, GradNorm 0.12815549817039468, Mem: 16231.0166015625
[TRAIN] Iter: 15700 Loss: 0.10666553676128387  PSNR: 9.719758987426758, Alpha: 1.0, GradNorm 0.3176775122912753, Mem: 16231.0166015625
[TRAIN] Iter: 15800 Loss: 0.12859101593494415  PSNR: 8.907894134521484, Alpha: 1.0, GradNorm 0.5560289026334183, Mem: 16231.0166015625
[TRAIN] Iter: 15900 Loss: 0.12745918333530426  PSNR: 8.9462890625, Alpha: 1.0, GradNorm 0.45775568285647383, Mem: 16231.0166015625
[TRAIN] Iter: 16000 Loss: 0.1165686696767807  PSNR: 9.334181785583496, Alpha: 1.0, GradNorm 0.1969352983093053, Mem: 16231.0166015625
[TRAIN] Iter: 16100 Loss: 0.12412309646606445  PSNR: 9.061473846435547, Alpha: 1.0, GradNorm 0.22896140998045006, Mem: 16231.0166015625
[TRAIN] Iter: 16200 Loss: 0.10722272843122482  PSNR: 9.697131156921387, Alpha: 0.9995447993278503, GradNorm 0.24688372856405155, Mem: 16231.0166015625
[TRAIN] Iter: 16300 Loss: 0.11820326745510101  PSNR: 9.273704528808594, Alpha: 0.9999955892562866, GradNorm 0.24862437736152973, Mem: 16231.0166015625
[TRAIN] Iter: 16400 Loss: 0.1203056201338768  PSNR: 9.19714069366455, Alpha: 0.9999999403953552, GradNorm 0.3697611575844965, Mem: 16231.0166015625
[TRAIN] Iter: 16500 Loss: 0.11766251176595688  PSNR: 9.293618202209473, Alpha: 0.9999643564224243, GradNorm 0.153134597495775, Mem: 16231.0166015625
[TRAIN] Iter: 16600 Loss: 0.11156713962554932  PSNR: 9.524637222290039, Alpha: 0.9994794726371765, GradNorm 0.16406352296706822, Mem: 16231.0166015625
[TRAIN] Iter: 16700 Loss: 0.10968859493732452  PSNR: 9.598384857177734, Alpha: 1.0, GradNorm 0.15862396311105836, Mem: 16231.0166015625
[TRAIN] Iter: 16800 Loss: 0.12371758371591568  PSNR: 9.075685501098633, Alpha: 0.9999996423721313, GradNorm 0.21279176799862848, Mem: 16231.0166015625
[TRAIN] Iter: 16900 Loss: 0.1103873923420906  PSNR: 9.570805549621582, Alpha: 0.9999954104423523, GradNorm 0.337454713290502, Mem: 16231.0166015625
[TRAIN] Iter: 17000 Loss: 0.09807378053665161  PSNR: 10.084470748901367, Alpha: 1.0, GradNorm 0.16881826894693183, Mem: 16231.0166015625
[TRAIN] Iter: 17100 Loss: 0.10821589082479477  PSNR: 9.657089233398438, Alpha: 1.0, GradNorm 0.25469110905415643, Mem: 16231.0166015625
[TRAIN] Iter: 17200 Loss: 0.11525002866983414  PSNR: 9.383589744567871, Alpha: 0.9999985098838806, GradNorm 0.33754233732613703, Mem: 16231.0166015625
[TRAIN] Iter: 17300 Loss: 0.10787124186754227  PSNR: 9.670943260192871, Alpha: 0.9999992847442627, GradNorm 0.24227034467244682, Mem: 16231.0166015625
[TRAIN] Iter: 17400 Loss: 0.114556223154068  PSNR: 9.40981388092041, Alpha: 1.0, GradNorm 0.2974391895695682, Mem: 16231.0166015625
[TRAIN] Iter: 17500 Loss: 0.1274086982011795  PSNR: 8.94800853729248, Alpha: 0.9999933242797852, GradNorm 0.3680080389766441, Mem: 16231.0166015625
[TRAIN] Iter: 17600 Loss: 0.10467270016670227  PSNR: 9.801666259765625, Alpha: 1.0, GradNorm 0.44694441892193226, Mem: 16231.0166015625
[TRAIN] Iter: 17700 Loss: 0.09717697650194168  PSNR: 10.124366760253906, Alpha: 0.9999998807907104, GradNorm 0.1815973993723961, Mem: 16231.0166015625
[TRAIN] Iter: 17800 Loss: 0.11156751215457916  PSNR: 9.524622917175293, Alpha: 1.0, GradNorm 0.324757752789523, Mem: 16231.0166015625
[TRAIN] Iter: 17900 Loss: 0.09958778321743011  PSNR: 10.017939567565918, Alpha: 0.9999938011169434, GradNorm 0.23413848532185405, Mem: 16231.0166015625
[TRAIN] Iter: 18000 Loss: 0.10226341336965561  PSNR: 9.902796745300293, Alpha: 0.9999998807907104, GradNorm 0.28788487408973407, Mem: 16231.0166015625
[TRAIN] Iter: 18100 Loss: 0.10035700350999832  PSNR: 9.98452377319336, Alpha: 1.0, GradNorm 0.24881911466744844, Mem: 16231.0166015625
[TRAIN] Iter: 18200 Loss: 0.11729878932237625  PSNR: 9.3070650100708, Alpha: 0.99971604347229, GradNorm 0.27805031498926425, Mem: 16231.0166015625
[TRAIN] Iter: 18300 Loss: 0.10251951962709427  PSNR: 9.891934394836426, Alpha: 0.9999992251396179, GradNorm 0.2991084600596755, Mem: 16231.0166015625
[TRAIN] Iter: 18400 Loss: 0.127616748213768  PSNR: 8.940922737121582, Alpha: 0.9999675750732422, GradNorm 0.514323670183261, Mem: 16231.0166015625
[TRAIN] Iter: 18500 Loss: 0.10338854789733887  PSNR: 9.855276107788086, Alpha: 0.9999997019767761, GradNorm 0.3219021880003977, Mem: 16231.0166015625
[TRAIN] Iter: 18600 Loss: 0.10911714285612106  PSNR: 9.62106990814209, Alpha: 0.9993371963500977, GradNorm 0.2991110608320433, Mem: 16231.0166015625
[TRAIN] Iter: 18700 Loss: 0.09967786818742752  PSNR: 10.014012336730957, Alpha: 1.0, GradNorm 0.2220010963136235, Mem: 16231.0166015625
[TRAIN] Iter: 18800 Loss: 0.10673416405916214  PSNR: 9.716964721679688, Alpha: 1.0, GradNorm 0.1766618048644741, Mem: 16231.0166015625
[TRAIN] Iter: 18900 Loss: 0.1032738983631134  PSNR: 9.86009407043457, Alpha: 0.9999998807907104, GradNorm 0.3112305210169871, Mem: 16231.0166015625
[TRAIN] Iter: 19000 Loss: 0.11247674375772476  PSNR: 9.489372253417969, Alpha: 0.9999971389770508, GradNorm 0.25523428676701554, Mem: 16231.0166015625
[TRAIN] Iter: 19100 Loss: 0.10522782057523727  PSNR: 9.778693199157715, Alpha: 1.0, GradNorm 0.4288756708993559, Mem: 16231.0166015625
[TRAIN] Iter: 19200 Loss: 0.10918985307216644  PSNR: 9.61817741394043, Alpha: 0.9999992847442627, GradNorm 0.41581082808866776, Mem: 16231.0166015625
[TRAIN] Iter: 19300 Loss: 0.11169600486755371  PSNR: 9.519623756408691, Alpha: 1.0, GradNorm 0.18400189354922594, Mem: 16231.0166015625
[TRAIN] Iter: 19400 Loss: 0.09729911386966705  PSNR: 10.118910789489746, Alpha: 0.9999996423721313, GradNorm 0.5012604016964921, Mem: 16231.0166015625
[TRAIN] Iter: 19500 Loss: 0.10867062211036682  PSNR: 9.638877868652344, Alpha: 1.0, GradNorm 0.270322976284673, Mem: 16231.0166015625
[TRAIN] Iter: 19600 Loss: 0.10563572496175766  PSNR: 9.76189136505127, Alpha: 0.9999927282333374, GradNorm 0.2984702505046201, Mem: 16231.0166015625
[TRAIN] Iter: 19700 Loss: 0.10651550441980362  PSNR: 9.725872039794922, Alpha: 0.9999980926513672, GradNorm 0.36643229198545024, Mem: 16231.0166015625
[TRAIN] Iter: 19800 Loss: 0.08996379375457764  PSNR: 10.459322929382324, Alpha: 1.0, GradNorm 0.16388701421499893, Mem: 16231.0166015625
[TRAIN] Iter: 19900 Loss: 0.11202779412269592  PSNR: 9.506742477416992, Alpha: 0.9999960660934448, GradNorm 0.33036207788703026, Mem: 16231.0166015625
Saved checkpoints at logs/rats_model/020000.tar
Head direction: -y
Pose 0: Valid indices count = 40061
Invalid bounding box for pose 1. Falling back to full image.
Pose 1: Valid indices count = 1391744
Pose 2: Valid indices count = 61791
Pose 3: Valid indices count = 1380
Invalid bounding box for pose 4. Falling back to full image.
Pose 4: Valid indices count = 1391744
Pose 5: Valid indices count = 179907
Pose 6: Valid indices count = 276148
Pose 7: Valid indices count = 200184
Pose 8: Valid indices count = 308052
Pose 9: Valid indices count = 167160
Pose 10: Valid indices count = 178724
Pose 11: Valid indices count = 179216
Pose 12: Valid indices count = 179463
Pose 13: Valid indices count = 177996
Pose 14: Valid indices count = 179340
Valid indices across all poses: [tensor([ 175236,  175237,  175238,  ..., 1075676, 1075677, 1075678]), tensor([      0,       1,       2,  ..., 1391741, 1391742, 1391743]), tensor([  1198,   1199,   1200,  ..., 636108, 636109, 636110]), tensor([ 63740,  63741,  63742,  ..., 673292, 673293, 673294]), tensor([      0,       1,       2,  ..., 1391741, 1391742, 1391743]), tensor([ 274622,  274623,  274624,  ..., 1148716, 1148717, 1148718]), tensor([264970, 264971, 264972,  ..., 960038, 960039, 960040]), tensor([173409, 173410, 173411,  ..., 778085, 778086, 778087]), tensor([   715,    716,    717,  ..., 685229, 685230, 685231]), tensor([153600, 153601, 153602,  ..., 710427, 710428, 710429]), tensor([315699, 315700, 315701,  ..., 966780, 966781, 966782]), tensor([315695, 315696, 315697,  ..., 961468, 961469, 961470]), tensor([314368, 314369, 314370,  ..., 962796, 962797, 962798]), tensor([319683, 319684, 319685,  ..., 968108, 968109, 968110]), tensor([315697, 315698, 315699,  ..., 965452, 965453, 965454])]
0 0.0008606910705566406
1 1.7741930484771729
2 61.85021138191223
3 2.750692844390869
4 0.055748701095581055
5 62.00614404678345
6 8.01432180404663
7 12.290805578231812
8 8.90088438987732
9 13.719370126724243
10 7.438813209533691
11 7.953811407089233
12 7.979013442993164
13 7.98876953125
14 7.920961618423462
Predicted image shape (th_rgbs): torch.Size([15, 3, 1048, 1328])
Ground truth image shape (th_gt): torch.Size([15, 3, 1048, 1328])
Any NaNs in th_rgbs: tensor(False, device='cpu')
Any NaNs in th_gt: tensor(False, device='cpu')
Any Infs in th_rgbs: tensor(False, device='cpu')
Any Infs in th_gt: tensor(False, device='cpu')
Evaluate PSNR: 13.2072809200591 (7.790275260666525), SSIM: 0.8203126192092896 (0.6534154874472687)
[TRAIN] Iter: 20000 Loss: 0.10027450323104858  PSNR: 9.988094329833984, Alpha: 1.0, GradNorm 0.23966780778138322, Mem: 16231.0166015625
[TRAIN] Iter: 20100 Loss: 0.0912993922829628  PSNR: 10.395320892333984, Alpha: 1.0, GradNorm 0.2150852082692309, Mem: 16231.0166015625
[TRAIN] Iter: 20200 Loss: 0.1091015636920929  PSNR: 9.621689796447754, Alpha: 0.9986953735351562, GradNorm 0.32669400551206024, Mem: 16231.0166015625
[TRAIN] Iter: 20300 Loss: 0.09767842292785645  PSNR: 10.10201358795166, Alpha: 1.0, GradNorm 0.30083788549615476, Mem: 16231.0166015625
[TRAIN] Iter: 20400 Loss: 0.13128763437271118  PSNR: 8.81776237487793, Alpha: 0.9999966621398926, GradNorm 0.3671211472866056, Mem: 16231.0166015625
[TRAIN] Iter: 20500 Loss: 0.10845375061035156  PSNR: 9.647554397583008, Alpha: 0.9999626874923706, GradNorm 0.29376030749709153, Mem: 16231.0166015625
[TRAIN] Iter: 20600 Loss: 0.11460571736097336  PSNR: 9.407937049865723, Alpha: 0.9999978542327881, GradNorm 0.5365762687892899, Mem: 16231.0166015625
[TRAIN] Iter: 20700 Loss: 0.11547856777906418  PSNR: 9.37498664855957, Alpha: 1.0, GradNorm 0.2719857308145977, Mem: 16231.0166015625
[TRAIN] Iter: 20800 Loss: 0.1140684187412262  PSNR: 9.428345680236816, Alpha: 1.0, GradNorm 0.21004186230191657, Mem: 16231.0166015625
[TRAIN] Iter: 20900 Loss: 0.10084574669599533  PSNR: 9.963423728942871, Alpha: 1.0, GradNorm 0.31735119619481383, Mem: 16231.0166015625
[TRAIN] Iter: 21000 Loss: 0.11237624287605286  PSNR: 9.493254661560059, Alpha: 1.0, GradNorm 0.3444712704046117, Mem: 16231.0166015625
[TRAIN] Iter: 21100 Loss: 0.11057664453983307  PSNR: 9.563365936279297, Alpha: 1.0, GradNorm 0.38786227435450726, Mem: 16231.0166015625
[TRAIN] Iter: 21200 Loss: 0.099388986825943  PSNR: 10.026617050170898, Alpha: 0.9999595880508423, GradNorm 0.2251794782987608, Mem: 16231.0166015625
[TRAIN] Iter: 21300 Loss: 0.1254432201385498  PSNR: 9.015527725219727, Alpha: 0.9997209310531616, GradNorm 0.33038573200946103, Mem: 16231.0166015625
[TRAIN] Iter: 21400 Loss: 0.10800589621067047  PSNR: 9.665525436401367, Alpha: 1.0, GradNorm 0.318680780142922, Mem: 16231.0166015625
[TRAIN] Iter: 21500 Loss: 0.11052996665239334  PSNR: 9.565199851989746, Alpha: 0.9999908208847046, GradNorm 0.2211449150445498, Mem: 16231.0166015625
[TRAIN] Iter: 21600 Loss: 0.09884960204362869  PSNR: 10.050251007080078, Alpha: 0.9993489980697632, GradNorm 0.32072691696616606, Mem: 16231.0166015625
[TRAIN] Iter: 21700 Loss: 0.09882638603448868  PSNR: 10.051270484924316, Alpha: 0.9995824694633484, GradNorm 0.3675468313700338, Mem: 16231.0166015625
[TRAIN] Iter: 21800 Loss: 0.10452193766832352  PSNR: 9.8079252243042, Alpha: 1.0, GradNorm 0.2559830974918273, Mem: 16231.0166015625
[TRAIN] Iter: 21900 Loss: 0.09673779457807541  PSNR: 10.144037246704102, Alpha: 0.9999985098838806, GradNorm 0.2171730900273954, Mem: 16231.0166015625
[TRAIN] Iter: 22000 Loss: 0.10271067917346954  PSNR: 9.883843421936035, Alpha: 0.9999926090240479, GradNorm 0.2464833763184728, Mem: 16231.0166015625
[TRAIN] Iter: 22100 Loss: 0.1019909530878067  PSNR: 9.914383888244629, Alpha: 1.0, GradNorm 0.350718445078003, Mem: 16231.0166015625
[TRAIN] Iter: 22200 Loss: 0.11523735523223877  PSNR: 9.384066581726074, Alpha: 0.9999985694885254, GradNorm 0.37820588675564687, Mem: 16231.0166015625
[TRAIN] Iter: 22300 Loss: 0.1085645854473114  PSNR: 9.643118858337402, Alpha: 0.9990336894989014, GradNorm 0.47039760405356174, Mem: 16231.0166015625
[TRAIN] Iter: 22400 Loss: 0.09801045805215836  PSNR: 10.087276458740234, Alpha: 0.9999998807907104, GradNorm 0.295736402376268, Mem: 16231.0166015625
[TRAIN] Iter: 22500 Loss: 0.10931000858545303  PSNR: 9.61340045928955, Alpha: 1.0, GradNorm 0.3770038999766272, Mem: 16231.0166015625
[TRAIN] Iter: 22600 Loss: 0.096975177526474  PSNR: 10.133393287658691, Alpha: 1.0, GradNorm 0.6025127293158149, Mem: 16231.0166015625
[TRAIN] Iter: 22700 Loss: 0.10264816880226135  PSNR: 9.88648796081543, Alpha: 1.0, GradNorm 0.27054116758907737, Mem: 16231.0166015625
[TRAIN] Iter: 22800 Loss: 0.10321645438671112  PSNR: 9.862510681152344, Alpha: 0.9999995231628418, GradNorm 0.2720191066134716, Mem: 16231.0166015625
[TRAIN] Iter: 22900 Loss: 0.09222669154405594  PSNR: 10.351433753967285, Alpha: 0.999991774559021, GradNorm 0.16952789509807686, Mem: 16231.0166015625
[TRAIN] Iter: 23000 Loss: 0.10149407386779785  PSNR: 9.935592651367188, Alpha: 1.0, GradNorm 0.20756863135137688, Mem: 16231.0166015625
[TRAIN] Iter: 23100 Loss: 0.10776101797819138  PSNR: 9.675382614135742, Alpha: 0.9999889135360718, GradNorm 0.38584659788594095, Mem: 16231.0166015625
[TRAIN] Iter: 23200 Loss: 0.10081334412097931  PSNR: 9.96481990814209, Alpha: 0.9999988079071045, GradNorm 0.40116047733746424, Mem: 16231.0166015625
[TRAIN] Iter: 23300 Loss: 0.10156182199716568  PSNR: 9.932695388793945, Alpha: 0.9999966621398926, GradNorm 0.6134771869881082, Mem: 16231.0166015625
[TRAIN] Iter: 23400 Loss: 0.1045118197798729  PSNR: 9.808345794677734, Alpha: 0.9999918341636658, GradNorm 0.21089813938954996, Mem: 16231.0166015625
[TRAIN] Iter: 23500 Loss: 0.10744143277406693  PSNR: 9.688282012939453, Alpha: 0.9999892115592957, GradNorm 0.35643579336046294, Mem: 16231.0166015625
[TRAIN] Iter: 23600 Loss: 0.10086169093847275  PSNR: 9.962738037109375, Alpha: 0.9999963641166687, GradNorm 0.3155992660391974, Mem: 16231.0166015625
[TRAIN] Iter: 23700 Loss: 0.0984908938407898  PSNR: 10.066039085388184, Alpha: 0.9999949336051941, GradNorm 0.22892908364252834, Mem: 16231.0166015625
[TRAIN] Iter: 23800 Loss: 0.09793698787689209  PSNR: 10.090532302856445, Alpha: 1.0, GradNorm 0.49948671544966944, Mem: 16231.0166015625
[TRAIN] Iter: 23900 Loss: 0.08717076480388641  PSNR: 10.596291542053223, Alpha: 0.9999944567680359, GradNorm 0.29965466326871165, Mem: 16231.0166015625
[TRAIN] Iter: 24000 Loss: 0.09388718754053116  PSNR: 10.273937225341797, Alpha: 1.0, GradNorm 0.29114936840302386, Mem: 16231.0166015625
[TRAIN] Iter: 24100 Loss: 0.09760954231023788  PSNR: 10.105077743530273, Alpha: 0.9999966025352478, GradNorm 0.3905570610798803, Mem: 16231.0166015625
[TRAIN] Iter: 24200 Loss: 0.09698743373155594  PSNR: 10.132844924926758, Alpha: 1.0, GradNorm 0.180372320884737, Mem: 16231.0166015625
[TRAIN] Iter: 24300 Loss: 0.10454080998897552  PSNR: 9.807141304016113, Alpha: 1.0, GradNorm 0.2885863126688316, Mem: 16231.0166015625
[TRAIN] Iter: 24400 Loss: 0.09736082702875137  PSNR: 10.116157531738281, Alpha: 0.9999980926513672, GradNorm 0.3611059722911623, Mem: 16231.0166015625
[TRAIN] Iter: 24500 Loss: 0.10600782930850983  PSNR: 9.746621131896973, Alpha: 0.9999591708183289, GradNorm 0.3657525306531865, Mem: 16231.0166015625
[TRAIN] Iter: 24600 Loss: 0.10497016459703445  PSNR: 9.78934097290039, Alpha: 0.9999597072601318, GradNorm 0.4606484715312213, Mem: 16231.0166015625
[TRAIN] Iter: 24700 Loss: 0.09580790996551514  PSNR: 10.185986518859863, Alpha: 1.0, GradNorm 0.27683677029529263, Mem: 16231.0166015625
[TRAIN] Iter: 24800 Loss: 0.10511847585439682  PSNR: 9.783209800720215, Alpha: 1.0, GradNorm 0.23513375077484136, Mem: 16231.0166015625
[TRAIN] Iter: 24900 Loss: 0.10329120606184006  PSNR: 9.859366416931152, Alpha: 0.9999833106994629, GradNorm 0.2544374742448312, Mem: 16231.0166015625
[TRAIN] Iter: 25000 Loss: 0.10781679302453995  PSNR: 9.673135757446289, Alpha: 1.0, GradNorm 0.3914527791502891, Mem: 16231.0166015625
[TRAIN] Iter: 25100 Loss: 0.10545723885297775  PSNR: 9.769235610961914, Alpha: 0.9987379908561707, GradNorm 0.34691916590492416, Mem: 16231.0166015625
[TRAIN] Iter: 25200 Loss: 0.09295883774757385  PSNR: 10.317092895507812, Alpha: 0.9998685121536255, GradNorm 0.1990871113465688, Mem: 16231.0166015625
[TRAIN] Iter: 25300 Loss: 0.09722850471735  PSNR: 10.122063636779785, Alpha: 0.9999997019767761, GradNorm 0.3873553768862599, Mem: 16231.0166015625
[TRAIN] Iter: 25400 Loss: 0.1089429035782814  PSNR: 9.628010749816895, Alpha: 1.0, GradNorm 0.40912033442186946, Mem: 16231.0166015625
[TRAIN] Iter: 25500 Loss: 0.09882946312427521  PSNR: 10.051135063171387, Alpha: 0.9999569654464722, GradNorm 0.49430335770655076, Mem: 16231.0166015625
[TRAIN] Iter: 25600 Loss: 0.09841525554656982  PSNR: 10.069375991821289, Alpha: 1.0, GradNorm 0.3052632548738521, Mem: 16231.0166015625
[TRAIN] Iter: 25700 Loss: 0.10174211114645004  PSNR: 9.924993515014648, Alpha: 0.999998927116394, GradNorm 0.3618564682007822, Mem: 16231.0166015625
[TRAIN] Iter: 25800 Loss: 0.10521279275417328  PSNR: 9.779314041137695, Alpha: 0.9999959468841553, GradNorm 0.21806791082793092, Mem: 16231.0166015625
[TRAIN] Iter: 25900 Loss: 0.11597975343465805  PSNR: 9.356178283691406, Alpha: 0.9999984502792358, GradNorm 0.34468757472856915, Mem: 16231.0166015625
[TRAIN] Iter: 26000 Loss: 0.10943133383989334  PSNR: 9.608583450317383, Alpha: 0.9999999403953552, GradNorm 0.31286249837564634, Mem: 16231.0166015625
[TRAIN] Iter: 26100 Loss: 0.09906414896249771  PSNR: 10.040834426879883, Alpha: 0.9999933242797852, GradNorm 0.31408998135049637, Mem: 16231.0166015625
[TRAIN] Iter: 26200 Loss: 0.0987907275557518  PSNR: 10.052838325500488, Alpha: 0.9992687106132507, GradNorm 0.2563015193261774, Mem: 16231.0166015625
[TRAIN] Iter: 26300 Loss: 0.11366568505764008  PSNR: 9.443706512451172, Alpha: 0.9999992847442627, GradNorm 0.2778627774365292, Mem: 16231.0166015625
[TRAIN] Iter: 26400 Loss: 0.09667477756738663  PSNR: 10.146867752075195, Alpha: 0.9999992251396179, GradNorm 0.28158736677080914, Mem: 16231.0166015625
[TRAIN] Iter: 26500 Loss: 0.09552762657403946  PSNR: 10.198710441589355, Alpha: 0.9999988079071045, GradNorm 0.2580432551144287, Mem: 16231.0166015625
[TRAIN] Iter: 26600 Loss: 0.0936262235045433  PSNR: 10.28602409362793, Alpha: 0.9999994039535522, GradNorm 0.4325723740648089, Mem: 16231.0166015625
[TRAIN] Iter: 26700 Loss: 0.09949181228876114  PSNR: 10.022126197814941, Alpha: 0.9999995231628418, GradNorm 0.3376965793993869, Mem: 16231.0166015625
[TRAIN] Iter: 26800 Loss: 0.09705353528261185  PSNR: 10.129886627197266, Alpha: 0.9999971389770508, GradNorm 0.32347000787385144, Mem: 16231.0166015625
[TRAIN] Iter: 26900 Loss: 0.10087471455335617  PSNR: 9.962176322937012, Alpha: 0.999514102935791, GradNorm 0.2622119013125548, Mem: 16231.0166015625
[TRAIN] Iter: 27000 Loss: 0.09892997145652771  PSNR: 10.046721458435059, Alpha: 0.9999985694885254, GradNorm 0.45142301321019895, Mem: 16231.0166015625
[TRAIN] Iter: 27100 Loss: 0.08965834230184555  PSNR: 10.474093437194824, Alpha: 0.9999963045120239, GradNorm 0.3259536913632119, Mem: 16231.0166015625
[TRAIN] Iter: 27200 Loss: 0.08994975686073303  PSNR: 10.460000038146973, Alpha: 0.9999974966049194, GradNorm 0.28257225432013233, Mem: 16231.0166015625
[TRAIN] Iter: 27300 Loss: 0.09521757066249847  PSNR: 10.21282958984375, Alpha: 0.9999932050704956, GradNorm 0.30147861839130735, Mem: 16231.0166015625
[TRAIN] Iter: 27400 Loss: 0.0945986807346344  PSNR: 10.24114990234375, Alpha: 0.9999755620956421, GradNorm 0.2748702456654735, Mem: 16231.0166015625
[TRAIN] Iter: 27500 Loss: 0.11041553318500519  PSNR: 9.569698333740234, Alpha: 0.99983811378479, GradNorm 0.48391057362340595, Mem: 16231.0166015625
[TRAIN] Iter: 27600 Loss: 0.09555988758802414  PSNR: 10.197243690490723, Alpha: 0.9999565482139587, GradNorm 0.3409328169841991, Mem: 16231.0166015625
[TRAIN] Iter: 27700 Loss: 0.09014815092086792  PSNR: 10.450430870056152, Alpha: 0.9999986886978149, GradNorm 0.6757438954577967, Mem: 16231.0166015625
[TRAIN] Iter: 27800 Loss: 0.11264582723379135  PSNR: 9.48284912109375, Alpha: 0.9979066848754883, GradNorm 0.2988701077905832, Mem: 16231.0166015625
[TRAIN] Iter: 27900 Loss: 0.10349098592996597  PSNR: 9.850974082946777, Alpha: 0.9999278783798218, GradNorm 0.3645994878388361, Mem: 16231.0166015625
[TRAIN] Iter: 28000 Loss: 0.10575226694345474  PSNR: 9.757102966308594, Alpha: 0.9999372959136963, GradNorm 0.4386774260433219, Mem: 16231.0166015625
[TRAIN] Iter: 28100 Loss: 0.08004631102085114  PSNR: 10.96658706665039, Alpha: 1.0, GradNorm 0.30395009746953294, Mem: 16231.0166015625
[TRAIN] Iter: 28200 Loss: 0.10029212385416031  PSNR: 9.98733139038086, Alpha: 0.9999679923057556, GradNorm 0.2742711125057289, Mem: 16231.0166015625
[TRAIN] Iter: 28300 Loss: 0.1089305505156517  PSNR: 9.62850284576416, Alpha: 0.9998641014099121, GradNorm 0.41915699888966856, Mem: 16231.0166015625
[TRAIN] Iter: 28400 Loss: 0.11429961770772934  PSNR: 9.419551849365234, Alpha: 1.0, GradNorm 0.3454204700072555, Mem: 16231.0166015625
[TRAIN] Iter: 28500 Loss: 0.09961770474910736  PSNR: 10.016634941101074, Alpha: 0.9999998807907104, GradNorm 0.4629148463398126, Mem: 16231.0166015625
[TRAIN] Iter: 28600 Loss: 0.10445670038461685  PSNR: 9.810636520385742, Alpha: 0.999994158744812, GradNorm 0.555403168106604, Mem: 16231.0166015625
[TRAIN] Iter: 28700 Loss: 0.11174122244119644  PSNR: 9.517865180969238, Alpha: 0.9999987483024597, GradNorm 0.5397682327793212, Mem: 16231.0166015625
[TRAIN] Iter: 28800 Loss: 0.09826593846082687  PSNR: 10.075969696044922, Alpha: 0.9999884366989136, GradNorm 0.2304077726099183, Mem: 16231.0166015625
[TRAIN] Iter: 28900 Loss: 0.09962905943393707  PSNR: 10.016139030456543, Alpha: 0.9996118545532227, GradNorm 0.21938290631242802, Mem: 16231.0166015625
[TRAIN] Iter: 29000 Loss: 0.09709067642688751  PSNR: 10.12822437286377, Alpha: 0.9999998807907104, GradNorm 0.3551431962051557, Mem: 16231.0166015625
[TRAIN] Iter: 29100 Loss: 0.10589984059333801  PSNR: 9.751046180725098, Alpha: 0.9999682307243347, GradNorm 0.3774403055171385, Mem: 16231.0166015625
[TRAIN] Iter: 29200 Loss: 0.08965158462524414  PSNR: 10.474420547485352, Alpha: 0.9999982714653015, GradNorm 0.2731549396297807, Mem: 16231.0166015625
[TRAIN] Iter: 29300 Loss: 0.08087272942066193  PSNR: 10.921977996826172, Alpha: 1.0, GradNorm 0.30308281696535727, Mem: 16231.0166015625
[TRAIN] Iter: 29400 Loss: 0.10383879393339157  PSNR: 9.836403846740723, Alpha: 0.9999946355819702, GradNorm 0.34521632975712435, Mem: 16231.0166015625
[TRAIN] Iter: 29500 Loss: 0.11044137179851532  PSNR: 9.568681716918945, Alpha: 0.9999991655349731, GradNorm 0.34179944544376634, Mem: 16231.0166015625
[TRAIN] Iter: 29600 Loss: 0.10044818371534348  PSNR: 9.980578422546387, Alpha: 0.999947726726532, GradNorm 0.3873147065152668, Mem: 16231.0166015625
[TRAIN] Iter: 29700 Loss: 0.09707658737897873  PSNR: 10.12885570526123, Alpha: 0.9999293088912964, GradNorm 0.5024466661128726, Mem: 16231.0166015625
[TRAIN] Iter: 29800 Loss: 0.09639067202806473  PSNR: 10.159649848937988, Alpha: 0.9999294281005859, GradNorm 0.35991931574434344, Mem: 16231.0166015625
[TRAIN] Iter: 29900 Loss: 0.09837961196899414  PSNR: 10.07094955444336, Alpha: 0.9999980926513672, GradNorm 0.21362306922079757, Mem: 16231.0166015625
Saved checkpoints at logs/rats_model/030000.tar
Head direction: -y
Pose 0: Valid indices count = 40061
Invalid bounding box for pose 1. Falling back to full image.
Pose 1: Valid indices count = 1391744
Pose 2: Valid indices count = 61791
Pose 3: Valid indices count = 1380
Invalid bounding box for pose 4. Falling back to full image.
Pose 4: Valid indices count = 1391744
Pose 5: Valid indices count = 179907
Pose 6: Valid indices count = 276148
Pose 7: Valid indices count = 200184
Pose 8: Valid indices count = 308052
Pose 9: Valid indices count = 167160
Pose 10: Valid indices count = 178724
Pose 11: Valid indices count = 179216
Pose 12: Valid indices count = 179463
Pose 13: Valid indices count = 177996
Pose 14: Valid indices count = 179340
Valid indices across all poses: [tensor([ 175236,  175237,  175238,  ..., 1075676, 1075677, 1075678]), tensor([      0,       1,       2,  ..., 1391741, 1391742, 1391743]), tensor([  1198,   1199,   1200,  ..., 636108, 636109, 636110]), tensor([ 63740,  63741,  63742,  ..., 673292, 673293, 673294]), tensor([      0,       1,       2,  ..., 1391741, 1391742, 1391743]), tensor([ 274622,  274623,  274624,  ..., 1148716, 1148717, 1148718]), tensor([264970, 264971, 264972,  ..., 960038, 960039, 960040]), tensor([173409, 173410, 173411,  ..., 778085, 778086, 778087]), tensor([   715,    716,    717,  ..., 685229, 685230, 685231]), tensor([153600, 153601, 153602,  ..., 710427, 710428, 710429]), tensor([315699, 315700, 315701,  ..., 966780, 966781, 966782]), tensor([315695, 315696, 315697,  ..., 961468, 961469, 961470]), tensor([314368, 314369, 314370,  ..., 962796, 962797, 962798]), tensor([319683, 319684, 319685,  ..., 968108, 968109, 968110]), tensor([315697, 315698, 315699,  ..., 965452, 965453, 965454])]
0 0.0013136863708496094
1 1.7756845951080322
2 61.8499231338501
3 2.75400710105896
4 0.05974173545837402
5 62.02131652832031
6 8.020567417144775
7 12.301053285598755
8 8.908029556274414
9 13.718801736831665
10 7.438689470291138
11 7.9565348625183105
12 7.985887289047241
13 7.997256755828857
14 7.922754287719727
Predicted image shape (th_rgbs): torch.Size([15, 3, 1048, 1328])
Ground truth image shape (th_gt): torch.Size([15, 3, 1048, 1328])
Any NaNs in th_rgbs: tensor(False, device='cpu')
Any NaNs in th_gt: tensor(False, device='cpu')
Any Infs in th_rgbs: tensor(False, device='cpu')
Any Infs in th_gt: tensor(False, device='cpu')
Evaluate PSNR: 13.507585556678725 (7.859377741220298), SSIM: 0.7784187197685242 (0.6514876868339912)
[TRAIN] Iter: 30000 Loss: 0.1154119148850441  PSNR: 9.377492904663086, Alpha: 0.999999463558197, GradNorm 0.3845664244882261, Mem: 16231.0166015625
[TRAIN] Iter: 30100 Loss: 0.08949203789234161  PSNR: 10.482155799865723, Alpha: 1.0, GradNorm 0.39639946893777783, Mem: 16231.0166015625
[TRAIN] Iter: 30200 Loss: 0.10529983043670654  PSNR: 9.77572250366211, Alpha: 0.9999998807907104, GradNorm 0.8288379369008836, Mem: 16231.0166015625
[TRAIN] Iter: 30300 Loss: 0.1034257709980011  PSNR: 9.85371208190918, Alpha: 0.9999990463256836, GradNorm 0.229706052583816, Mem: 16231.0166015625
[TRAIN] Iter: 30400 Loss: 0.10557278245687485  PSNR: 9.764480590820312, Alpha: 0.9999966621398926, GradNorm 0.389631881317054, Mem: 16231.0166015625
[TRAIN] Iter: 30500 Loss: 0.09287428855895996  PSNR: 10.321044921875, Alpha: 0.9995376467704773, GradNorm 0.41276248502626084, Mem: 16231.0166015625
[TRAIN] Iter: 30600 Loss: 0.10725347697734833  PSNR: 9.695886611938477, Alpha: 0.9998049139976501, GradNorm 0.742890691511459, Mem: 16231.0166015625
[TRAIN] Iter: 30700 Loss: 0.09155741333961487  PSNR: 10.383064270019531, Alpha: 0.999767005443573, GradNorm 0.42628722981420614, Mem: 16231.0166015625
[TRAIN] Iter: 30800 Loss: 0.11745672672986984  PSNR: 9.301220893859863, Alpha: 0.9999940395355225, GradNorm 0.4394365834172655, Mem: 16231.0166015625
[TRAIN] Iter: 30900 Loss: 0.10338018089532852  PSNR: 9.855627059936523, Alpha: 0.9999988079071045, GradNorm 0.4129208603904478, Mem: 16231.0166015625
[TRAIN] Iter: 31000 Loss: 0.09568393230438232  PSNR: 10.191609382629395, Alpha: 0.9999997019767761, GradNorm 0.5181783407304607, Mem: 16231.0166015625
[TRAIN] Iter: 31100 Loss: 0.09640083461999893  PSNR: 10.15919303894043, Alpha: 0.9956789016723633, GradNorm 0.4494587920171993, Mem: 16231.0166015625
[TRAIN] Iter: 31200 Loss: 0.09414968639612198  PSNR: 10.261810302734375, Alpha: 1.0, GradNorm 0.3455480407747153, Mem: 16231.0166015625
[TRAIN] Iter: 31300 Loss: 0.08845389634370804  PSNR: 10.532830238342285, Alpha: 0.9999896883964539, GradNorm 0.745630299057566, Mem: 16231.0166015625
[TRAIN] Iter: 31400 Loss: 0.10620815306901932  PSNR: 9.738421440124512, Alpha: 0.9999987483024597, GradNorm 0.2775387900072258, Mem: 16231.0166015625
[TRAIN] Iter: 31500 Loss: 0.10271487385034561  PSNR: 9.8836669921875, Alpha: 0.9999955892562866, GradNorm 0.6443036388424871, Mem: 16231.0166015625
[TRAIN] Iter: 31600 Loss: 0.09825894236564636  PSNR: 10.076278686523438, Alpha: 1.0, GradNorm 0.7027241136516946, Mem: 16231.0166015625
[TRAIN] Iter: 31700 Loss: 0.08673201501369476  PSNR: 10.618205070495605, Alpha: 0.9999868869781494, GradNorm 0.38091632777849654, Mem: 16231.0166015625
[TRAIN] Iter: 31800 Loss: 0.10588476061820984  PSNR: 9.751666069030762, Alpha: 1.0, GradNorm 0.36243016399803696, Mem: 16231.0166015625
[TRAIN] Iter: 31900 Loss: 0.08190318942070007  PSNR: 10.86699104309082, Alpha: 0.9999979734420776, GradNorm 0.22775184348270078, Mem: 16231.0166015625
[TRAIN] Iter: 32000 Loss: 0.07517079263925552  PSNR: 11.239508628845215, Alpha: 1.0, GradNorm 0.5628823316698843, Mem: 16231.0166015625
[TRAIN] Iter: 32100 Loss: 0.10654847323894501  PSNR: 9.724527359008789, Alpha: 0.9997369050979614, GradNorm 0.45317574295434043, Mem: 16231.0166015625
[TRAIN] Iter: 32200 Loss: 0.09166917949914932  PSNR: 10.377766609191895, Alpha: 0.9999999403953552, GradNorm 0.38233733905903083, Mem: 16231.0166015625
[TRAIN] Iter: 32300 Loss: 0.09241696447134018  PSNR: 10.342482566833496, Alpha: 1.0, GradNorm 0.2983608021049005, Mem: 16231.0166015625
[TRAIN] Iter: 32400 Loss: 0.08666567504405975  PSNR: 10.621528625488281, Alpha: 0.999954104423523, GradNorm 0.5663140313325886, Mem: 16231.0166015625
[TRAIN] Iter: 32500 Loss: 0.09062507748603821  PSNR: 10.427515983581543, Alpha: 0.9999946355819702, GradNorm 0.35589940906349854, Mem: 16231.0166015625
[TRAIN] Iter: 32600 Loss: 0.08726771920919418  PSNR: 10.591463088989258, Alpha: 0.9999960660934448, GradNorm 0.2932949652810736, Mem: 16231.0166015625
[TRAIN] Iter: 32700 Loss: 0.10777703672647476  PSNR: 9.674737930297852, Alpha: 0.9999743700027466, GradNorm 0.3536451287121382, Mem: 16231.0166015625
[TRAIN] Iter: 32800 Loss: 0.10283259302377701  PSNR: 9.878691673278809, Alpha: 0.9999224543571472, GradNorm 0.5225358744396322, Mem: 16231.0166015625
[TRAIN] Iter: 32900 Loss: 0.09374295175075531  PSNR: 10.28061294555664, Alpha: 0.9998976588249207, GradNorm 0.29379043064180504, Mem: 16231.0166015625
[TRAIN] Iter: 33000 Loss: 0.09602738916873932  PSNR: 10.176048278808594, Alpha: 0.9999985098838806, GradNorm 0.4273373451310118, Mem: 16231.0166015625
[TRAIN] Iter: 33100 Loss: 0.10175744444131851  PSNR: 9.924339294433594, Alpha: 0.9999996423721313, GradNorm 0.5677096876819449, Mem: 16231.0166015625
[TRAIN] Iter: 33200 Loss: 0.09164028614759445  PSNR: 10.379135131835938, Alpha: 1.0, GradNorm 0.5546950353641288, Mem: 16231.0166015625
[TRAIN] Iter: 33300 Loss: 0.09041576832532883  PSNR: 10.4375581741333, Alpha: 0.9999958872795105, GradNorm 0.2657267980306414, Mem: 16231.0166015625
[TRAIN] Iter: 33400 Loss: 0.09065617620944977  PSNR: 10.426026344299316, Alpha: 1.0, GradNorm 0.5475324392465499, Mem: 16231.0166015625
[TRAIN] Iter: 33500 Loss: 0.09755779802799225  PSNR: 10.107379913330078, Alpha: 1.0, GradNorm 0.4795786627105556, Mem: 16231.0166015625
[TRAIN] Iter: 33600 Loss: 0.07842125743627548  PSNR: 11.05566120147705, Alpha: 0.9999985694885254, GradNorm 0.3006664838798019, Mem: 16231.0166015625
[TRAIN] Iter: 33700 Loss: 0.08021912723779678  PSNR: 10.957220077514648, Alpha: 0.9997488856315613, GradNorm 0.41716769743961113, Mem: 16231.0166015625
[TRAIN] Iter: 33800 Loss: 0.08180920034646988  PSNR: 10.871977806091309, Alpha: 0.9999997615814209, GradNorm 0.5930406335211185, Mem: 16231.0166015625
[TRAIN] Iter: 33900 Loss: 0.10437450557947159  PSNR: 9.814055442810059, Alpha: 0.9999959468841553, GradNorm 0.433187825726782, Mem: 16231.0166015625
[TRAIN] Iter: 34000 Loss: 0.09748511761426926  PSNR: 10.110616683959961, Alpha: 0.9999475479125977, GradNorm 0.5252885239839339, Mem: 16231.0166015625
[TRAIN] Iter: 34100 Loss: 0.09102891385555267  PSNR: 10.40820598602295, Alpha: 0.9998586177825928, GradNorm 0.3477379877362728, Mem: 16231.0166015625
[TRAIN] Iter: 34200 Loss: 0.10235845297574997  PSNR: 9.898762702941895, Alpha: 0.9999968409538269, GradNorm 0.39860764917758224, Mem: 16231.0166015625
[TRAIN] Iter: 34300 Loss: 0.08216870576143265  PSNR: 10.852934837341309, Alpha: 0.999995231628418, GradNorm 0.28360637693582763, Mem: 16231.0166015625
[TRAIN] Iter: 34400 Loss: 0.07727273553609848  PSNR: 11.119736671447754, Alpha: 0.9999980330467224, GradNorm 0.6323017946358284, Mem: 16231.0166015625
[TRAIN] Iter: 34500 Loss: 0.09972446411848068  PSNR: 10.011982917785645, Alpha: 0.9994550943374634, GradNorm 0.4147123838997763, Mem: 16231.0166015625
[TRAIN] Iter: 34600 Loss: 0.09914631396532059  PSNR: 10.037235260009766, Alpha: 1.0, GradNorm 0.2833882552326278, Mem: 16231.0166015625
[TRAIN] Iter: 34700 Loss: 0.10364977270364761  PSNR: 9.844316482543945, Alpha: 0.9999994039535522, GradNorm 0.5213536113131065, Mem: 16231.0166015625
[TRAIN] Iter: 34800 Loss: 0.10811750590801239  PSNR: 9.661040306091309, Alpha: 0.9999999403953552, GradNorm 0.3182738506870117, Mem: 16231.0166015625
[TRAIN] Iter: 34900 Loss: 0.07838084548711777  PSNR: 11.057900428771973, Alpha: 0.999934196472168, GradNorm 0.39047700497156335, Mem: 16231.0166015625
[TRAIN] Iter: 35000 Loss: 0.09390325099229813  PSNR: 10.273193359375, Alpha: 0.9999918937683105, GradNorm 0.398932608553632, Mem: 16231.0166015625
[TRAIN] Iter: 35100 Loss: 0.0938589945435524  PSNR: 10.27524185180664, Alpha: 0.999839723110199, GradNorm 0.3813591497211686, Mem: 16231.0166015625
[TRAIN] Iter: 35200 Loss: 0.09064037352800369  PSNR: 10.426783561706543, Alpha: 0.9999960660934448, GradNorm 0.5022190367559232, Mem: 16231.0166015625
[TRAIN] Iter: 35300 Loss: 0.09088201820850372  PSNR: 10.415220260620117, Alpha: 1.0, GradNorm 0.4895835355339522, Mem: 16231.0166015625
[TRAIN] Iter: 35400 Loss: 0.09022074937820435  PSNR: 10.446935653686523, Alpha: 1.0, GradNorm 0.42579561106028374, Mem: 16231.0166015625
[TRAIN] Iter: 35500 Loss: 0.09299292415380478  PSNR: 10.31550121307373, Alpha: 0.9999974966049194, GradNorm 0.44914421227404383, Mem: 16231.0166015625
[TRAIN] Iter: 35600 Loss: 0.07861756533384323  PSNR: 11.044804573059082, Alpha: 1.0, GradNorm 0.2353269219960381, Mem: 16231.0166015625
[TRAIN] Iter: 35700 Loss: 0.08951649814844131  PSNR: 10.480969429016113, Alpha: 0.9999675750732422, GradNorm 0.45700760308218874, Mem: 16231.0166015625
[TRAIN] Iter: 35800 Loss: 0.0993385836482048  PSNR: 10.028820037841797, Alpha: 0.9999997615814209, GradNorm 0.4262536013487489, Mem: 16231.0166015625
[TRAIN] Iter: 35900 Loss: 0.0944339856505394  PSNR: 10.248716354370117, Alpha: 0.9999997019767761, GradNorm 0.413120081891466, Mem: 16231.0166015625
[TRAIN] Iter: 36000 Loss: 0.10386941581964493  PSNR: 9.835123062133789, Alpha: 0.999980628490448, GradNorm 0.3262520956937636, Mem: 16231.0166015625
[TRAIN] Iter: 36100 Loss: 0.09353039413690567  PSNR: 10.290472030639648, Alpha: 1.0, GradNorm 0.3018899796107241, Mem: 16231.0166015625
[TRAIN] Iter: 36200 Loss: 0.0851510614156723  PSNR: 10.698099136352539, Alpha: 0.9999944567680359, GradNorm 0.739387135106731, Mem: 16231.0166015625
[TRAIN] Iter: 36300 Loss: 0.09150467067956924  PSNR: 10.385566711425781, Alpha: 1.0, GradNorm 0.2711821192263388, Mem: 16231.0166015625
[TRAIN] Iter: 36400 Loss: 0.08793573826551437  PSNR: 10.558345794677734, Alpha: 0.9999997019767761, GradNorm 0.5316446994520174, Mem: 16231.0166015625
[TRAIN] Iter: 36500 Loss: 0.07895717769861221  PSNR: 11.026083946228027, Alpha: 0.9999424815177917, GradNorm 0.29409390139833297, Mem: 16231.0166015625
[TRAIN] Iter: 36600 Loss: 0.10329727083444595  PSNR: 9.859110832214355, Alpha: 1.0, GradNorm 0.4458717508768777, Mem: 16231.0166015625
[TRAIN] Iter: 36700 Loss: 0.0978570207953453  PSNR: 10.094079971313477, Alpha: 0.9999982714653015, GradNorm 0.42048650476616095, Mem: 16231.0166015625
[TRAIN] Iter: 36800 Loss: 0.08073180168867111  PSNR: 10.929553985595703, Alpha: 0.9998397827148438, GradNorm 0.38550195457115555, Mem: 16231.0166015625
[TRAIN] Iter: 36900 Loss: 0.09728045016527176  PSNR: 10.119744300842285, Alpha: 1.0, GradNorm 0.24024996665329623, Mem: 16231.0166015625
[TRAIN] Iter: 37000 Loss: 0.0796048492193222  PSNR: 10.99060344696045, Alpha: 0.9999658465385437, GradNorm 0.5854134720583776, Mem: 16231.0166015625
[TRAIN] Iter: 37100 Loss: 0.09309589117765427  PSNR: 10.310694694519043, Alpha: 0.9999999403953552, GradNorm 0.4922745054045177, Mem: 16231.0166015625
[TRAIN] Iter: 37200 Loss: 0.09262154251337051  PSNR: 10.332880020141602, Alpha: 0.9999963641166687, GradNorm 0.6272994279100012, Mem: 16231.0166015625
[TRAIN] Iter: 37300 Loss: 0.09289056807756424  PSNR: 10.320283889770508, Alpha: 0.9985488653182983, GradNorm 0.3260534325655193, Mem: 16231.0166015625
[TRAIN] Iter: 37400 Loss: 0.08341056853532791  PSNR: 10.787788391113281, Alpha: 1.0, GradNorm 0.6582705115897425, Mem: 16231.0166015625
[TRAIN] Iter: 37500 Loss: 0.08897267282009125  PSNR: 10.50743293762207, Alpha: 0.9999997019767761, GradNorm 0.307175939147924, Mem: 16231.0166015625
[TRAIN] Iter: 37600 Loss: 0.08969468623399734  PSNR: 10.472332954406738, Alpha: 0.9999999403953552, GradNorm 0.369300043488286, Mem: 16231.0166015625
[TRAIN] Iter: 37700 Loss: 0.09195417910814285  PSNR: 10.364285469055176, Alpha: 0.9999278783798218, GradNorm 0.47461045996499385, Mem: 16231.0166015625
[TRAIN] Iter: 37800 Loss: 0.07830281555652618  PSNR: 11.062226295471191, Alpha: 1.0, GradNorm 0.3864924995392227, Mem: 16231.0166015625
[TRAIN] Iter: 37900 Loss: 0.08176735043525696  PSNR: 10.874200820922852, Alpha: 0.9998884201049805, GradNorm 0.41086005964828665, Mem: 16231.0166015625
[TRAIN] Iter: 38000 Loss: 0.09093943983316422  PSNR: 10.412477493286133, Alpha: 1.0, GradNorm 0.3313512794556996, Mem: 16231.0166015625
[TRAIN] Iter: 38100 Loss: 0.09034851938486099  PSNR: 10.440789222717285, Alpha: 1.0, GradNorm 0.5116551377068869, Mem: 16231.0166015625
[TRAIN] Iter: 38200 Loss: 0.09137541055679321  PSNR: 10.391706466674805, Alpha: 1.0, GradNorm 0.3251977701323722, Mem: 16231.0166015625
[TRAIN] Iter: 38300 Loss: 0.08868749439716339  PSNR: 10.52137565612793, Alpha: 0.9998002052307129, GradNorm 0.466108961598343, Mem: 16231.0166015625
[TRAIN] Iter: 38400 Loss: 0.10022053867578506  PSNR: 9.990432739257812, Alpha: 0.9999997019767761, GradNorm 0.5183683039345838, Mem: 16231.0166015625
[TRAIN] Iter: 38500 Loss: 0.08566456288099289  PSNR: 10.67198657989502, Alpha: 0.9999971389770508, GradNorm 0.3484077524343756, Mem: 16231.0166015625
[TRAIN] Iter: 38600 Loss: 0.08890536427497864  PSNR: 10.510720252990723, Alpha: 0.9999998807907104, GradNorm 0.28571254949579533, Mem: 16231.0166015625
[TRAIN] Iter: 38700 Loss: 0.10132024437189102  PSNR: 9.943037033081055, Alpha: 0.9997397661209106, GradNorm 0.37177362405275877, Mem: 16231.0166015625
[TRAIN] Iter: 38800 Loss: 0.07647610455751419  PSNR: 11.164742469787598, Alpha: 1.0, GradNorm 0.4880019517503027, Mem: 16231.0166015625
[TRAIN] Iter: 38900 Loss: 0.07897370308637619  PSNR: 11.025174140930176, Alpha: 1.0, GradNorm 0.37775400888176863, Mem: 16231.0166015625
[TRAIN] Iter: 39000 Loss: 0.0878586545586586  PSNR: 10.562153816223145, Alpha: 0.9998986124992371, GradNorm 0.6225038059917786, Mem: 16231.0166015625
[TRAIN] Iter: 39100 Loss: 0.07944158464670181  PSNR: 10.99952220916748, Alpha: 0.9999998807907104, GradNorm 0.3406919199437093, Mem: 16231.0166015625
[TRAIN] Iter: 39200 Loss: 0.08123437315225601  PSNR: 10.90260124206543, Alpha: 0.9999388456344604, GradNorm 0.39096976652545845, Mem: 16231.0166015625
[TRAIN] Iter: 39300 Loss: 0.10245126485824585  PSNR: 9.89482593536377, Alpha: 0.9999999403953552, GradNorm 0.4856305070145527, Mem: 16231.0166015625
[TRAIN] Iter: 39400 Loss: 0.08605656772851944  PSNR: 10.652159690856934, Alpha: 0.9999994039535522, GradNorm 0.46915576073602877, Mem: 16231.0166015625
[TRAIN] Iter: 39500 Loss: 0.09178724884986877  PSNR: 10.372176170349121, Alpha: 1.0, GradNorm 0.37021009740978594, Mem: 16231.0166015625
[TRAIN] Iter: 39600 Loss: 0.09096717089414597  PSNR: 10.411152839660645, Alpha: 0.9999801516532898, GradNorm 0.5426024382434854, Mem: 16231.0166015625
[TRAIN] Iter: 39700 Loss: 0.10495974123477936  PSNR: 9.789772987365723, Alpha: 0.9999982714653015, GradNorm 0.3176445729510599, Mem: 16231.0166015625
[TRAIN] Iter: 39800 Loss: 0.08632423728704453  PSNR: 10.638671875, Alpha: 0.9999997019767761, GradNorm 0.3826975794613735, Mem: 16231.0166015625
[TRAIN] Iter: 39900 Loss: 0.08963757753372192  PSNR: 10.475098609924316, Alpha: 1.0, GradNorm 0.43545295084464963, Mem: 16231.0166015625
Saved checkpoints at logs/rats_model/040000.tar
Head direction: -y
Pose 0: Valid indices count = 40061
Invalid bounding box for pose 1. Falling back to full image.
Pose 1: Valid indices count = 1391744
Pose 2: Valid indices count = 61791
Pose 3: Valid indices count = 1380
Invalid bounding box for pose 4. Falling back to full image.
Pose 4: Valid indices count = 1391744
Pose 5: Valid indices count = 179907
Pose 6: Valid indices count = 276148
Pose 7: Valid indices count = 200184
Pose 8: Valid indices count = 308052
Pose 9: Valid indices count = 167160
Pose 10: Valid indices count = 178724
Pose 11: Valid indices count = 179216
Pose 12: Valid indices count = 179463
Pose 13: Valid indices count = 177996
Pose 14: Valid indices count = 179340
Valid indices across all poses: [tensor([ 175236,  175237,  175238,  ..., 1075676, 1075677, 1075678]), tensor([      0,       1,       2,  ..., 1391741, 1391742, 1391743]), tensor([  1198,   1199,   1200,  ..., 636108, 636109, 636110]), tensor([ 63740,  63741,  63742,  ..., 673292, 673293, 673294]), tensor([      0,       1,       2,  ..., 1391741, 1391742, 1391743]), tensor([ 274622,  274623,  274624,  ..., 1148716, 1148717, 1148718]), tensor([264970, 264971, 264972,  ..., 960038, 960039, 960040]), tensor([173409, 173410, 173411,  ..., 778085, 778086, 778087]), tensor([   715,    716,    717,  ..., 685229, 685230, 685231]), tensor([153600, 153601, 153602,  ..., 710427, 710428, 710429]), tensor([315699, 315700, 315701,  ..., 966780, 966781, 966782]), tensor([315695, 315696, 315697,  ..., 961468, 961469, 961470]), tensor([314368, 314369, 314370,  ..., 962796, 962797, 962798]), tensor([319683, 319684, 319685,  ..., 968108, 968109, 968110]), tensor([315697, 315698, 315699,  ..., 965452, 965453, 965454])]
